1. WHY ACOLYTE? - The Problem Statement (2.5 minutes)
[Slide 3 - Data to Actions STILL Takes Time]
"Good morning Let me begin by addressing why we need Acolyte in today's data landscape.
Currently, data to actions still takes significant time across organizations working with large-scale  data. We face three critical challenges:
Complex Infrastructure: Large datasets require specialized tools, pipelines, and infrastructure setup. These systems need distributed computing frameworks and careful architecture planning that can take weeks to configure properly.
Specific Skillsets: To work effectively with these datasets, organizations need dedicated data scientists costing 1-3% of revenue for SMBs with $100M-$500M annual revenue. These specialists are expensive and increasingly difficult to retain.
Long Lead Times: The process remains very manual and iterative for discovering final insights. From initial data request to actionable business recommendation, organizations face weeks or months of lead time.
This is especially true in situations where the complexity of data is high - particularly with payments lifecycle data. The result? Critical business decisions are delayed, opportunities are missed, and competitive advantages erode while organizations wait for insights that should be immediate.
This is why we need a fundamental shift in how data professionals working with payment data approach advanced analytics."

2. WHAT IS ACOLYTE? - The Solution (2 minutes)
[Slide 4 - Introducing Acolyte]
"Acolyte is your own agentic ML scientist - a comprehensive platform designed for every data professional who works with Visa data.
Vision: Democratize advanced analytics by providing ML science capabilities directly to every data professional.
Mission: Eliminate barriers between data and actionable insights, reducing time-to-value from months to minutes.
Deep Insights: Our agents automatically analyze payment data and generate insights and recommendations without human intervention. Imagine fraud patterns being detected and flagged before they impact merchants, or customer churn predictions generated proactively.
AI Assistant: Natural language queries that let anyone - from risk analysts to business executives - ask complex questions about payment data and get sophisticated answers instantly. No SQL required, no waiting for data science teams.
Swarm ML: This is where the magic happens - our agents automatically build and deploy machine learning models for deep queries that need hours of compute. While teams focus on strategy, Swarm ML is running sophisticated analysis in the background.
The transformation is dramatic: What used to take data science teams weeks now happens in minutes. What required specialized skills now works with simple English questions. What needed manual processes now runs automatically."

3. ACOLYTE ARCHITECTURE :
"Let me walk you through the Acolyte architecture and how the different agents work together to deliver insights."

We start with the Dataset Onboarding Agent.
When a user uploads or onboards a dataset, this agent immediately gets to work. It triggers a sub-agent called the Analytics Datadocs Creator Agent.

This sub-agent uses in-house Python tools to generate Datadocs — mini insights about the dataset, such as patterns, distributions, and key metrics. Once created, these Datadocs are embedded and stored in the Datadocs Embedding Table for quick retrieval later.

Next, as soon as the onboarding process finishes, the Deep Insight Agent is triggered in the background. This is a fully autonomous agent that generates hypotheses about the dataset and produces deeper, more complex insights. These are stored in the Insights Database for future use.

When a user submits a query, the request first goes to the Search and Reason Agent, also known as the Agentic Search Agent.
This isn’t just a standard retrieval-augmented generation (RAG) system. It has a Feedback Node to refine queries and ensure the most relevant Datadocs are retrieved. It also uses Memory Nodes to connect past context with the current query, enabling more nuanced answers.

If the Search and Reason Agent cannot fully answer the query, the Agentic EDA agent steps in.
This agent identifies the right dataset, writes the necessary analysis code, executes it in the Code Runtime Environment, and produces visualizations to address the query.

All agents are supported by a shared memory layer, allowing them to learn and improve over time as they interact with more data and queries.

Finally, the system is scalable — it supports PySpark for large datasets, ensuring performance is maintained even at big-data scale.

"In short, Acolyte is a coordinated system of specialized agents — from onboarding and automated insights to advanced search, reasoning, and code-driven analysis — all powered by memory and built to scale."
