# app.py
from flask import Flask, request, jsonify, render_template
from datetime import datetime, timedelta
import uuid
from genaieda.db import init_db, get_db, Session, Conversation
from genaieda.backend import get_chat

app = Flask(__name__)
init_db(app)
db = get_db()
chatobj = get_chat()

SESSION_TIMEOUT = timedelta(minutes=30)

def get_or_create_session():
    session_id = request.cookies.get("session_id")
    session = Session.query.filter_by(id=session_id).first() if session_id else None
    if session and datetime.utcnow() - session.last_activity <= SESSION_TIMEOUT:
        session.last_activity = datetime.utcnow()
    else:
        session_id = str(uuid.uuid4())
        session = Session(id=session_id, last_activity=datetime.utcnow())
        db.session.add(session)
    db.session.commit()
    return session_id

@app.after_request
def after_request(response):
    response.set_cookie("session_id", request.cookies.get("session_id") or get_or_create_session(), httponly=True, secure=True, samesite="Strict")
    return response

@app.route("/")
def home():
    return render_template("index.html", session_id=get_or_create_session())

@app.route("/get_session_id", methods=["GET"])
def get_session_id():
    return jsonify({"session_id": get_or_create_session()})

@app.route("/chat", methods=["POST"])
def chat():
    session_id = request.json.get("sessionId")
    if not session_id:
        return jsonify({"text": "Session ID is missing"}), 400
    user_input = request.json.get("message")
    answer = chatobj.answer(user_input, session_id)
    conversation = Conversation(session_id=session_id, timestamp=datetime.utcnow(), user_message=user_input)
    conversation.set_agent_response(answer)
    db.session.add(conversation)
    db.session.commit()
    return jsonify({"text": answer})

# chat.py
from langgraph_core.messages import TooMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, END
from genaieda.backend.abstract import Chat
from .utils import EdaState, timeit
from .agents import visualization_node, coder_node, bigdata_node, retriever_node, meta_node
import os

class AgenticChat(Chat):
    def __init__(self):
        self.graph = self._compile()

    def _compile(self):
        builder = StateGraph(EdaState)

        def add_assistant_node(name, assistant):
            def call_assistant(state):
                state["messages"] = state["messages"][-1:]
                response = assistant.invoke(state)
                state["messages"][-1] = response["messages"][-1]
                return state

            builder.add_node(name, call_assistant)
            builder.add_edge(name, "meta")

        builder.add_node("meta", meta_node())
        builder.set_entry_point("meta")

        add_assistant_node("retriever", retriever_node())
        add_assistant_node("coder", coder_node())
        add_assistant_node("bigdata", bigdata_node())
        add_assistant_node("visualizer", visualization_node())

        memory = MemorySaver()
        return builder.compile(checkpointer=memory)

    @timeit("total")
    def answer(self, question: str, session_id: str) -> str:
        config = {"configurable": {"thread_id": session_id}}
        already_printed_messages = []
        for chunk in self.graph.stream({"messages": question}, config=config, stream_mode="values", subgraphs=True):
            if os.environ.get("DEBUG_MESSAGES") == "True":
                message = chunk["messages"][-1]
                if message not in already_printed_messages:
                    already_printed_messages.append(message)
                    print(message.pretty_print())
            state = chunk[1]
        return state["messages"][-1].content.replace("[ENCODED_PLOT_HERE]", state.get("image_str", ""))

# supervisor.py
from typing import Literal
from pydantic import BaseModel, Field
from langgraph.types import Command
from langgraph.graph import END
from genaieda.backend.langgraph.utils import EdaState
from .base import LLMNode
from eda_memory_store import EDAMemoryStore
from episodic_store import EpisodicStore

members = ["retriever", "coder", "bigdata", "visualizer"]
options = members + ["FINISH", "QUESTION"]

class MetaAgent(LLMNode):
    """
    You are a supervisor AI that routes user queries to the right assistant.
    Use semantic and episodic memory blocks below to make decisions.

    --- SEMANTIC MEMORY ---
    {{retrieved_memory}}

    --- EPISODIC MEMORY ---
    {{episodic_trace}}
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.semantic_store = EDAMemoryStore("postgresql://user:pass@localhost:5432/edadb")
        self.episodic_store = EpisodicStore("postgresql://user:pass@localhost:5432/edadb")

    def __call__(self, state: EdaState) -> Command:
        session_id = state.configurable.get("thread_id")
        user_id = "default_user"
        user_message = state.user_question

        semantic_block = "\n".join(self.semantic_store.retrieve(session_id, user_message)) or "None"
        episodic_trace = "\n".join(f"{e['role']}: {e['message']}" for e in self.episodic_store.get_last_n(session_id)) or "None"

        # Inject both memories into system prompt
        self.llm.prefix_messages = [{
            "role": "system",
            "content": self.__class__.__doc__.replace("{{retrieved_memory}}", semantic_block).replace("{{episodic_trace}}", episodic_trace)
        }]

        response = super().__call__(state)
        goto = response.next
        self.semantic_store.save(session_id, user_id, user_message)
        self.episodic_store.save_event(session_id, "user", user_message)

        content = response.task
        if goto == "FINISH":
            self.episodic_store.save_event(session_id, "metaagent", response.answer)
            content = response.answer
        elif goto == "QUESTION":
            self.episodic_store.save_event(session_id, "metaagent", response.question)
            content = response.question
        else:
            self.episodic_store.save_event(session_id, "metaagent", response.task)

        return Command(goto=goto, update={"messages": self._create_ai_message(content)})
